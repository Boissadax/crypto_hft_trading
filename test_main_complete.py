#!/usr/bin/env python3
"""
Test du HFT Engine v3 avec donnÃ©es synthÃ©tiques pour validation rapide
"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))

from main import HFTEngineComplete

def test_synthetic_data():
    """Test rapide avec donnÃ©es synthÃ©tiques."""
    print("ğŸš€ " + "="*60)
    print("   HFT ENGINE v3 - TEST RAPIDE")
    print("   Avec DonnÃ©es SynthÃ©tiques")
    print("="*62)
    
    try:
        # Initialiser avec des symboles qui forceront l'utilisation de donnÃ©es synthÃ©tiques
        engine = HFTEngineComplete(
            dataset_id="TEST",  # Dataset inexistant pour forcer synthÃ©tique
            symbols=["BTC", "ETH"],
            verbose=True
        )
        
        # Forcer l'utilisation de donnÃ©es synthÃ©tiques en modifiant temporairement
        print("\nğŸ“Š GÃ©nÃ©ration de donnÃ©es synthÃ©tiques...")
        data = engine._generate_synthetic_data()
        
        print(f"âœ… DonnÃ©es gÃ©nÃ©rÃ©es: {list(data.keys())}")
        for symbol, df in data.items():
            print(f"   {symbol}: {len(df):,} points de donnÃ©es")
        
        # Test feature engineering avec donnÃ©es synthÃ©tiques
        print("\nâš™ï¸ Test d'ingÃ©nierie des features...")
        try:
            features = engine.engineer_features(data)
            print(f"âœ… Features gÃ©nÃ©rÃ©es: {features.shape}")
        except Exception as e:
            print(f"âŒ Feature engineering Ã©chouÃ©: {e}")
            # Continuer quand mÃªme
            features = None
        
        # Test Transfer Entropy
        print("\nğŸ”¬ Test de Transfer Entropy...")
        te_results = engine.analyze_transfer_entropy(data)
        if te_results:
            print(f"âœ… Transfer Entropy calculÃ© pour {len(te_results.get('pairwise_results', {}))} paires")
        
        # Test causality
        print("\nğŸ“ˆ Test de causalitÃ©...")
        causality_results = engine.perform_causality_tests(data)
        if causality_results:
            print(f"âœ… Tests de causalitÃ©: {list(causality_results.keys())}")
        
        # Test ML (si features disponibles)
        if features is not None and not features.empty:
            print("\nğŸ¤– Test ML...")
            ml_results = engine.train_ml_models(features)
            if ml_results:
                print(f"âœ… ModÃ¨les ML: {list(ml_results.keys())}")
        
        # Test backtesting
        print("\nğŸ¯ Test de backtesting...")
        backtest_results = engine.run_comprehensive_backtest(data)
        if backtest_results and 'comparison' in backtest_results:
            comparison_df = backtest_results['comparison']
            print(f"âœ… Backtesting: {len(comparison_df)} stratÃ©gies testÃ©es")
            
            # Afficher les rÃ©sultats
            print("\nğŸ“Š RÃ‰SULTATS DES STRATÃ‰GIES:")
            ranked = comparison_df.sort_values('Total Return', ascending=False)
            for i, (strategy, row) in enumerate(ranked.iterrows(), 1):
                print(f"   {i}. {strategy}: {row['Total Return']:.2f}%")
        
        # Test visualisations
        print("\nğŸ“Š Test de visualisations...")
        try:
            engine.create_comprehensive_visualizations()
            print("âœ… Visualisations crÃ©Ã©es")
        except Exception as e:
            print(f"âš ï¸  Visualisations partielles: {e}")
        
        # Sauvegarde des rÃ©sultats
        print("\nğŸ’¾ Sauvegarde des rÃ©sultats...")
        engine.save_results()
        
        # RÃ©sumÃ© final
        engine._print_final_summary()
        
        return True
        
    except Exception as e:
        print(f"âŒ Test Ã©chouÃ©: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_synthetic_data()
    print(f"\n{'âœ… TEST RÃ‰USSI' if success else 'âŒ TEST Ã‰CHOUÃ‰'}")
